{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d9400bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "839b9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('spam.csv', encoding=\"ISO-8859-1\")\n",
    "df = pd.DataFrame(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cecc7232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: v1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check class distribution\n",
    "classes = df[df.columns[0]]\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "560ea20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     ham\n",
      "1     ham\n",
      "2    spam\n",
      "3     ham\n",
      "4     ham\n",
      "5    spam\n",
      "6     ham\n",
      "7     ham\n",
      "8    spam\n",
      "9    spam\n",
      "Name: v1, dtype: object\n",
      "[0 0 1 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# convert class labels to binary values, 0 = ham  1 = spam\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(classes)\n",
    "\n",
    "# quick check\n",
    "print(classes[:10])\n",
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "212159db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Go until jurong point, crazy.. Available only ...\n",
      "1                        Ok lar... Joking wif u oni...\n",
      "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    U dun say so early hor... U c already then say...\n",
      "4    Nah I don't think he goes to usf, he lives aro...\n",
      "5    FreeMsg Hey there darling it's been 3 week's n...\n",
      "6    Even my brother is not like to speak with me. ...\n",
      "7    As per your request 'Melle Melle (Oru Minnamin...\n",
      "8    WINNER!! As a valued network customer you have...\n",
      "9    Had your mobile 11 months or more? U R entitle...\n",
      "Name: v2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# store SMS message data\n",
    "text_messages = df[df.columns[1]]\n",
    "print(text_messages[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a54be03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kirus\\AppData\\Local\\Temp\\ipykernel_14360\\1359283326.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = text_messages.str.replace(r'^\\w+@[a-zA-Z_]+?\\.[a-zA-Z]{2,3}$', 'emailaddr')\n",
      "C:\\Users\\kirus\\AppData\\Local\\Temp\\ipykernel_14360\\1359283326.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n",
      "C:\\Users\\kirus\\AppData\\Local\\Temp\\ipykernel_14360\\1359283326.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = text_messages.str.replace(r'£|\\$', 'moneysymb')\n",
      "C:\\Users\\kirus\\AppData\\Local\\Temp\\ipykernel_14360\\1359283326.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = text_messages.str.replace(r'^[2-9]\\d{2}-\\d{3}-\\d{4}$', 'phonenum')\n",
      "C:\\Users\\kirus\\AppData\\Local\\Temp\\ipykernel_14360\\1359283326.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = text_messages.str.replace(r'\\d+(\\.\\d+)?', 'num')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# replace email addresses with 'emailaddr\n",
    "processed = text_messages.str.replace(r'^\\w+@[a-zA-Z_]+?\\.[a-zA-Z]{2,3}$', 'emailaddr')\n",
    "\n",
    "# replace urls with 'webaddress'\n",
    "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n",
    "# replace money symbols with 'moneysymb'\n",
    "processed = text_messages.str.replace(r'£|\\$', 'moneysymb')\n",
    "\n",
    "# replace 10 digit phone numbers with 'phonenum'\n",
    "processed = text_messages.str.replace(r'^[2-9]\\d{2}-\\d{3}-\\d{4}$', 'phonenum')\n",
    "\n",
    "# replace normal numbers with 'num'\n",
    "processed = text_messages.str.replace(r'\\d+(\\.\\d+)?', 'num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e17c8719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kirus\\AppData\\Local\\Temp\\ipykernel_14360\\3300460673.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
      "C:\\Users\\kirus\\AppData\\Local\\Temp\\ipykernel_14360\\3300460673.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'\\s+', ' ')\n",
      "C:\\Users\\kirus\\AppData\\Local\\Temp\\ipykernel_14360\\3300460673.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39877a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go until jurong point crazy available only in ...\n",
       "1                              ok lar joking wif u oni\n",
       "2    free entry in num a wkly comp to win fa cup fi...\n",
       "3          u dun say so early hor u c already then say\n",
       "4    nah i don t think he goes to usf he lives arou...\n",
       "Name: v2, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "processed = processed.str.lower()\n",
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2aaca76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kirus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40ff0060",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5ca6fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go jurong point crazi avail bugi n great world...\n",
       "1                                ok lar joke wif u oni\n",
       "2    free entri num wkli comp win fa cup final tkt ...\n",
       "3                  u dun say earli hor u c alreadi say\n",
       "4                 nah think goe usf live around though\n",
       "Name: v2, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    ps.stem(term) for term in x.split()))\n",
    "\n",
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "443bf085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2865aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kirus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "225bb239",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f44be5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 6534\n",
      "Most common words: [('num', 2959), ('u', 1192), ('call', 672), ('go', 453), ('get', 452), ('ur', 385), ('gt', 318), ('lt', 316), ('å', 303), ('come', 301)]\n"
     ]
    }
   ],
   "source": [
    "print('Number of words: {}'.format(len(all_words)))\n",
    "print('Most common words: {}'.format(all_words.most_common(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88d638b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(all_words.keys())[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2993621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "jurong\n",
      "point\n",
      "crazi\n",
      "avail\n",
      "bugi\n",
      "n\n",
      "great\n",
      "world\n",
      "la\n",
      "e\n",
      "buffet\n",
      "cine\n",
      "got\n",
      "amor\n",
      "wat\n"
     ]
    }
   ],
   "source": [
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# example\n",
    "features = find_features(processed[0])\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81ef0067",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = list(zip(processed, Y))\n",
    "\n",
    "# define a seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(messages)\n",
    "\n",
    "# call find_features function for each SMS message\n",
    "featuresets = [(find_features(text), label) for (text, label) in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a622d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# split the data into training and testing datasets\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac3a362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 4179\n",
      "Testing: 1393\n"
     ]
    }
   ],
   "source": [
    "print('Training:',len(training))\n",
    "print('Testing:',len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ce6d734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 98.42067480258436\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "\n",
    "# train the model on the training data\n",
    "model.train(training)\n",
    "\n",
    "# and test on the testing dataset!\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "print(\"SVC Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cb59f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kirus\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 93.61091170136396\n",
      "Decision Tree Accuracy: 97.34386216798278\n",
      "Random Forest Accuracy: 98.42067480258436\n",
      "Logistic Regression Accuracy: 98.42067480258436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb4a67aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: Accuracy: 98.42067480258436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "\n",
    "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be231380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kirus\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "txt_features, labels = zip(*testing)\n",
    "\n",
    "prediction = nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27eadac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1202\n",
      "           1       1.00      0.85      0.92       191\n",
      "\n",
      "    accuracy                           0.98      1393\n",
      "   macro avg       0.99      0.92      0.95      1393\n",
      "weighted avg       0.98      0.98      0.98      1393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>ham</th>\n",
       "      <td>1202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>29</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                  ham spam\n",
       "actual ham       1202    0\n",
       "       spam        29  162"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(labels, prediction))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(labels, prediction),\n",
    "    index = [['actual', 'actual'], ['ham', 'spam']],\n",
    "    columns = [['predicted', 'predicted'], ['ham', 'spam']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877ed2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
